{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10968821,"sourceType":"datasetVersion","datasetId":6814178}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/babaksh/googlestocklstm-tensorflow?scriptVersionId=227949386\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction\n\nThis notebook aims to predict Google stock prices using Long Short-Term Memory (LSTM) neural networks. It explores multiple configurations by incorporating Simple Moving Averages (SMAs) of different window sizes as features to enhance predictive performance. The analysis compares:\n\n- A baseline model using raw price data (no SMAs).\n- Models with individual SMAs (5, 7, 9, 11, 13, 15, 17 days).\n- A model with all SMAs combined.\n- Combinations of the best-performing SMAs.\n\nThe goal is to assess how these configurations impact prediction accuracy and forecast stock prices for the next 10 days.","metadata":{}},{"cell_type":"markdown","source":"# Required Libraries\n\nThe following libraries are essential for this project:\n\n- **Keras**: Builds and trains LSTM neural network models.\n- **NumPy**: Handles numerical computations.\n- **Pandas**: Manages data manipulation and preprocessing.\n- **yfinance**: Typically fetches stock data (though here, data is loaded from a CSV).\n- **datetime**: Processes date and time data.\n- **Matplotlib**: Creates static visualizations.\n- **Plotly**: Generates interactive charts.\n- **Scikit-learn**: Provides tools for scaling data (`MinMaxScaler`) and calculating evaluation metrics.\n\nThese libraries enable data handling, model development, and result visualization.","metadata":{}},{"cell_type":"code","source":"import keras\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom IPython.display import HTML, display\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Configurations\n\nKey hyperparameters and settings guide the modeling process:\n\n- **EPOCH**: 700 training iterations.\n- **RATIO**: 80% training data, 20% testing data (0.8).\n- **WINDOW_SIZE**: Default SMA window (21 days), used in Bollinger Bands.\n- **NUM_STD**: 4 standard deviations for Bollinger Bands.\n- **BATCH_SIZE**: 128 samples per gradient update.\n- **LSTM_UNIT**: 70 units in the first LSTM layer.\n- **DROPOUT_RATE**: 30% dropout to prevent overfitting.\n- **FUTURE_DAYS**: 10 days for future predictions.\n- **SEQ_LENGTH**: 45-days input sequences for LSTM.\n- **target_col**: 'Close' (target variable).\n- **LEARNING_RATE**: 0.001 Learning rate in LSTM model.\n- **L2_REGULARIZER**: 0.0001 L2 regularization in LSTM model.\n\nThese settings ensure consistency across data preparation, model architecture, and training.","metadata":{}},{"cell_type":"code","source":"# Configs\nEPOCH = 700\nRATIO = 0.8\nWINDOW_SIZE = 21\nNUM_STD = 4\nBATCH_SIZE = 128\nLSTM_UNIT = 70\nDROPOUT_RATE = 0.3\nFUTURE_DAYS = 10\nSEQ_LENGTH = 45  # Use 45 days to predict the next day\ntarget_col = 'Close'\nLEARNING_RATE = 0.001\nL2_REGULARIZER = 0.0001\nPATIENCE = 50\ntoday = datetime.today()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing and Visualization\n\n## Data Preprocessing\n\nThis section prepares the Google stock dataset:\n\n- **Loading Data**: Data is loaded from `Google_2025.csv`.\n- **Future Data**: The last 10 rows are reserved for future prediction evaluation.\n- **Date Handling**: 'Date' column is converted to datetime format.\n- **Calculating SMAs**: SMAs are computed for 5, 7, 9, 11, 13, 15, and 17 days.\n- **Missing Values**: Initial SMA NaNs are filled with corresponding closing prices.\n- **Column Removal**: Drops 'Dividends', 'Stock Splits', and 'Volume'.","metadata":{}},{"cell_type":"code","source":"# Load data\ndf = pd.read_csv('/kaggle/input/googlestock/Google_2025-03-22.csv')\nlast_n_days_data = df.iloc[-FUTURE_DAYS:]  # Only the last FUTURE_DAYS rows\ndf = df.iloc[:-FUTURE_DAYS]  # All rows except the last FUTURE_DAYS\n\n# Data cleaning\n# Convert the datetime column to datetime object\ndf['Date'] = pd.to_datetime(df['Date'], utc=True)\nlast_n_days_data['Date'] = pd.to_datetime(last_n_days_data['Date'], utc=True)\n\n# Extract the date part\ndf['Date'] = df['Date'].dt.date\nlast_n_days_data['Date'] = last_n_days_data['Date'].dt.date\n\ndf['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\nlast_n_days_data['Date'] = pd.to_datetime(last_n_days_data['Date'], format='%Y-%m-%d')\n\ndf[\"5d_sma\"] = df[\"Close\"].rolling(5).mean()\ndf[\"7d_sma\"] = df[\"Close\"].rolling(7).mean()\ndf[\"9d_sma\"] = df[\"Close\"].rolling(9).mean()\ndf[\"11d_sma\"] = df[\"Close\"].rolling(11).mean()\ndf[\"13d_sma\"] = df[\"Close\"].rolling(13).mean()\ndf[\"15d_sma\"] = df[\"Close\"].rolling(15).mean()\ndf[\"17d_sma\"] = df[\"Close\"].rolling(17).mean()\n\n# Check missing values\nprint(f\"Missing values: {df.isnull().sum().sum()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['5d_sma'] = df['5d_sma'].fillna(df['Close'])\ndf['7d_sma'] = df['7d_sma'].fillna(df['Close'])\ndf['9d_sma'] = df['9d_sma'].fillna(df['Close'])\ndf['11d_sma'] = df['11d_sma'].fillna(df['Close'])\ndf['13d_sma'] = df['13d_sma'].fillna(df['Close'])\ndf['15d_sma'] = df['15d_sma'].fillna(df['Close'])\ndf['17d_sma'] = df['17d_sma'].fillna(df['Close'])\n\n# Check missing values after refinements\nprint(f\"Missing values: {df.isnull().sum().sum()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_df = df[df['Date'] >= '2025-01-01']\nplot_january = df[(df['Date'] >= '2025-01-01') & (df['Date'] <= '2025-01-31')]\nplot_last_30_days = df.iloc[-30:]\n\ndf = df.drop('Dividends', axis=1)  # Remove constant column\ndf = df.drop('Stock Splits', axis=1)  # Remove constant column\ndf = df.drop('Volume', axis=1)  # Remove redundant column\n\nlast_n_days_data = last_n_days_data.drop('Dividends', axis=1)  # Remove constant column\nlast_n_days_data = last_n_days_data.drop('Stock Splits', axis=1)  # Remove constant column\nlast_n_days_data = last_n_days_data.drop('Volume', axis=1)  # Remove redundant column","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.tail(15))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Visualization\n\nVisualizations explore stock price trends:\n\n- **Historical Closing Prices**: Line plot of closing prices over time.\n- **2025 Prices**: Plot of open, high, low, and close prices for 2025.\n- **January 2025 Prices**: Focused view of January 2025.\n- **Last 30 Days**: Recent price trends.\n- **Candlestick Chart with SMAs**: Interactive Plotly chart of 2025 data with candlesticks and SMA overlays (5D to 17D).\n\nThese steps produce cleaned data and insightful visualizations.","metadata":{}},{"cell_type":"code","source":"def plot_historical_data(dataframe, title):\n    plt.figure(figsize=(12, 6))\n    plt.plot(dataframe['Date'], dataframe['Close'], label='Closing Price', color='blue')\n    plt.plot(dataframe['Date'], dataframe['High'], label='High Price', color='green')\n    plt.plot(dataframe['Date'], dataframe['Low'], label='Low Price', color='red')\n    plt.plot(dataframe['Date'], dataframe['Open'], label='Opening Price', color='black')\n    plt.title(title)\n    plt.xlabel('Date')\n    plt.ylabel('Price (USD)')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize closing price\nplt.figure(figsize=(12, 6))\nplt.plot(df['Close'])\nplt.title('Google Stock Closing Price History')\nplt.xlabel('Date')\nplt.ylabel('Closing Price (USD)')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 2025 price\nplot_historical_data(plot_df, 'Google Stock High Price History - 2025')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize Jan 2025 price\nplot_historical_data(plot_january, 'Google Stock High Price History - January 2025')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize Last 30 days price\nplot_historical_data(plot_last_30_days, 'Google Stock High Price History - The last 30 days')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the candlestick chart\nfig = go.Figure(data=[go.Candlestick(\n    x=plot_df['Date'],  # Date on the x-axis\n    open=plot_df['Open'],  # Open prices\n    high=plot_df['High'],  # High prices\n    low=plot_df['Low'],  # Low prices\n    close=plot_df['Close'],  # Close prices\n    name='Google Stock Market in 2025'\n)])\n\n# Customize the layout\nfig.update_layout(\n    title='Google Stock Price History - 2025',\n    xaxis_title='Date',\n    yaxis_title='Price (USD)',\n    xaxis_rangeslider_visible=False\n)\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['Close'], line_color='green', name='Close', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['5d_sma'], line_color='yellow', name='5D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['7d_sma'], line_color='aqua', name='7D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['9d_sma'], line_color='red', name='9D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['11d_sma'], line_color='cyan', name='11D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['13d_sma'], line_color='darkgreen', name='5D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['15d_sma'], line_color='darkblue', name='7D-SMA', mode='lines'))\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['17d_sma'], line_color='darkred', name='9D-SMA', mode='lines'))\n\n# Show the plot\ndisplay(HTML(fig.to_html(include_plotlyjs=True)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Simple Data without SMA\n\nThis section creates a baseline LSTM model using raw price data:\n\n- **Sequence Creation**: Generates 60-day sequences (X) and targets (y).\n- **Feature Selection**:\n  - Features: 'Open', 'High', 'Low', 'Close'.\n  - Normalized using `MinMaxScaler` (0 to 1).\n  - Split into 80% training, 20% testing sets.\n\nThe baseline excludes SMAs to evaluate performance without trend indicators.","metadata":{}},{"cell_type":"code","source":"# Create sequences\ndef create_sequences(data, seq_length, features):\n    X, y = [], []\n    for i in range(seq_length, len(data)):\n        X.append(data[i-seq_length:i])\n        y.append(data[i, features.index(target_col)])\n    return np.array(X), np.array(y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature selection and normalization\ndef feature_selection(dataframe, features):\n    scaler = MinMaxScaler(feature_range=(0,1))\n    scaled_data = scaler.fit_transform(dataframe[features])\n    \n    X, y = create_sequences(scaled_data, SEQ_LENGTH, features)\n    \n    # Train-Test split\n    train_size = int(RATIO * len(X))\n    X_train, X_test = X[:train_size], X[train_size:]\n    y_train, y_test = y[:train_size], y[train_size:]\n\n    print(X_train.shape, X_test.shape)\n    print(y_train.shape, y_test.shape)\n    \n    return X_train, X_test, y_train, y_test, scaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_simple = ['Open', 'High', 'Low', 'Close']\nX_train_simple, X_test_simple, y_train_simple, y_test_simple, scaler_simple = feature_selection(df, features_simple)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Bollinger Bands\n\n## Overview\n\nBollinger Bands indicate volatility using an SMA and standard deviations:\n\n- **Purpose**: Identify overbought/oversold conditions.\n- **Calculation**:\n  - SMA (rolling mean) over 15 days.\n  - Rolling standard deviation over 15 days.\n  - Upper Band = SMA + (4 × Std Dev).\n  - Lower Band = SMA - (4 × Std Dev).","metadata":{}},{"cell_type":"code","source":"def calculate_bollinger_bands(dataframe, nd_sma, model_name):\n    # Calculate rolling mean and standard deviation 5d\n    rolling_mean = np.convolve(dataframe[nd_sma], np.ones(WINDOW_SIZE)/WINDOW_SIZE, mode='valid')\n    rolling_std = np.std([dataframe[nd_sma][i:i+WINDOW_SIZE] for i in range(len(dataframe[nd_sma])-WINDOW_SIZE+1)], axis=1)\n     \n    # Calculate Bollinger Bands 5d\n    upper_band = rolling_mean + NUM_STD * rolling_std\n    lower_band = rolling_mean - NUM_STD * rolling_std\n    \n    # plot_bollingerBands(rolling_mean, upper_band, lower_band, nd_sma, model_name)\n    plt.figure(figsize=(12,6))\n    plt.plot(dataframe['Close'], label='Stock Price')\n    plt.plot(rolling_mean, label=f'{model_name}', color='black')\n    plt.plot(upper_band, label='Upper Bollinger Band', color='green')\n    plt.plot(lower_band, label='Lower Bollinger Band', color='red')\n    plt.fill_between(np.arange(WINDOW_SIZE-1, len(dataframe[f'{nd_sma}'])), lower_band, upper_band, color='blue', alpha=0.2)\n    plt.title(f'Bollinger Bands ({model_name})')\n    plt.xlabel('Days')\n    plt.ylabel('Price')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Implementation\n\nFor each SMA (5D to 17D):\n- **Data**: Includes 'Open', 'High', 'Low', 'Close', and the SMA.\n- **Visualization**: Plots price, SMA, and bands.\n\nThis provides volatility insights for each SMA configuration.","metadata":{}},{"cell_type":"markdown","source":"## 5,7,9,11,13,15,17 SMA\n\nThis section prepares data with all SMAs combined:\n\n- **Features**: 'Open', 'High', 'Low', 'Close', plus SMAs (5D to 17D).\n- **Process**: Normalizes data, creates sequences, splits into training/testing sets.\n- **Purpose**: Tests if multiple SMAs improve predictions.\n\nData is sorted by date and indexed for time series consistency.","metadata":{}},{"cell_type":"markdown","source":"### 5D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_5d = ['Open', 'High', 'Low', 'Close', '5d_sma']\nX_train_5d, X_test_5d, y_train_5d, y_test_5d, scaler_5d = feature_selection(df, features_5d)\n\n# Calculate and Visualize Bollinger Bands 5d price\ncalculate_bollinger_bands(df, '5d_sma', '5D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_7d = ['Open', 'High', 'Low', 'Close', '7d_sma']\nX_train_7d, X_test_7d, y_train_7d, y_test_7d, scaler_7d = feature_selection(df, features_7d)\n\n# Calculate and Visualize Bollinger Bands 7d price\ncalculate_bollinger_bands(df, '7d_sma', '7D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 9D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_9d = ['Open', 'High', 'Low', 'Close', '9d_sma']\nX_train_9d, X_test_9d, y_train_9d, y_test_9d, scaler_9d = feature_selection(df, features_9d)\n\n# Calculate and Visualize Bollinger Bands 9d price\ncalculate_bollinger_bands(df, '9d_sma', '9D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 11D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_11d = ['Open', 'High', 'Low', 'Close', '11d_sma']\nX_train_11d, X_test_11d, y_train_11d, y_test_11d, scaler_11d = feature_selection(df, features_11d)\n\n# Calculate and Visualize Bollinger Bands 11d price\ncalculate_bollinger_bands(df, '11d_sma', '11D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 13D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_13d = ['Open', 'High', 'Low', 'Close', '13d_sma']\nX_train_13d, X_test_13d, y_train_13d, y_test_13d, scaler_13d = feature_selection(df, features_13d)\n\n# Calculate and Visualize Bollinger Bands 13d price\ncalculate_bollinger_bands(df, '13d_sma', '13D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 15D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_15d = ['Open', 'High', 'Low', 'Close', '15d_sma']\nX_train_15d, X_test_15d, y_train_15d, y_test_15d, scaler_15d = feature_selection(df, features_15d)\n\n# Calculate and Visualize Bollinger Bands 15d price\ncalculate_bollinger_bands(df, '15d_sma', '15D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 17D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_17d = ['Open', 'High', 'Low', 'Close', '17d_sma']\nX_train_17d, X_test_17d, y_train_17d, y_test_17d, scaler_17d = feature_selection(df, features_17d)\n\n# Calculate and Visualize Bollinger Bands 17d price\ncalculate_bollinger_bands(df, '17d_sma', '17D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5-17D SMA","metadata":{}},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_all = ['Open', 'High', 'Low', 'Close', '5d_sma', '7d_sma', '9d_sma', '11d_sma', '13d_sma', '15d_sma', '17d_sma']\nX_train_all, X_test_all, y_train_all, y_test_all, scaler_all = feature_selection(df, features_all)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.sort_values('Date').set_index('Date')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Architecture\n\nThe LSTM model is defined as:\n\n- **First LSTM Layer**: LSTM_UNIT units in configuration, returns sequences, L2 kernel and recurrent regularizer in configuration.\n- **Dropout**: DROPOUT_RATE in configuration.\n- **Second LSTM Layer**: LSTM_UNIT units, no sequences returned, L2 kernel and recurrent regularizer in configuration.\n- **Dropout**: DROPOUT_RATE in configuration.\n- **Dense Layer**: LSTM_UNIT/2 unit, L2 kernel regularizer in configuration.\n- **Dense Layer**: 1 unit, L2 kernel regularizer in configuration (output).\n\nThis structure captures temporal patterns while reducing overfitting.","metadata":{}},{"cell_type":"code","source":"def create_model(X_train_nd):\n    lstm_unit_1 = LSTM_UNIT\n    lstm_unit_2 = int(LSTM_UNIT/2)\n    model = Sequential([\n        LSTM(units=lstm_unit_1,\n             return_sequences=False,\n             input_shape=(X_train_nd.shape[1],\n                          X_train_nd.shape[2]),\n             kernel_regularizer=l2(L2_REGULARIZER),\n             recurrent_regularizer=l2(L2_REGULARIZER)),\n        Dropout(DROPOUT_RATE),\n        \n        # Dense(units=lstm_unit_2, kernel_regularizer=l2(L2_REGULARIZER)),\n        Dense(units=1, kernel_regularizer=l2(L2_REGULARIZER))\n    ])\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_simple = create_model(X_train_simple)\nmodel_simple.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_5d = create_model(X_train_5d)\nmodel_7d = create_model(X_train_7d)\nmodel_9d = create_model(X_train_9d)\nmodel_11d = create_model(X_train_11d)\nmodel_13d = create_model(X_train_13d)\nmodel_15d = create_model(X_train_15d)\nmodel_17d = create_model(X_train_17d)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_all = create_model(X_train_all)\nmodel_all.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training the Models\n\nModels are trained for each configuration:\n\n- **Compilation**: Adam optimizer, MSE loss.\n- **Training**:\n  - Batch size: 128.\n  - Epochs: 500.\n  - Validation: 20% of data.\n- **Configurations**:\n  - Simple data.\n  - Individual SMAs (5D to 17D).\n  - All SMAs combined.\n- **Visualization**: Plots training/validation loss.\n\nThis produces trained models for evaluation.","metadata":{}},{"cell_type":"code","source":"def train_model(model, X_train, y_train, X_val, y_val, model_name):\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mean_squared_error')\n    \n    # Define callbacks\n    early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=PATIENCE)\n    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n    \n    history = model.fit(\n        X_train, y_train,\n        batch_size=BATCH_SIZE,\n        epochs=EPOCH,\n        validation_data=(X_val, y_val),\n        # callbacks=[early_stopping, reduce_lr, model_checkpoint],\n        verbose=0\n    )\n    \n    return history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training loss\ndef plot_model_data(history, model_name):\n    plt.figure(figsize=(12, 6))\n    plt.plot(history.history['loss'], label='Train')\n    plt.plot(history.history['val_loss'], label='Test')\n    plt.title(f'Model Loss - {model_name}')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_simple = train_model(model_simple, X_train_simple, y_train_simple, X_test_simple, y_test_simple, 'no_sma')\nplot_model_data(history_simple, 'Without SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_5d = train_model(model_5d, X_train_5d, y_train_5d, X_test_5d, y_test_5d, '5d_sma')\nplot_model_data(history_5d, '5D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_7d = train_model(model_7d, X_train_7d, y_train_7d, X_test_7d, y_test_7d, '7d_sma')\nplot_model_data(history_7d, '7D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_9d = train_model(model_9d, X_train_9d, y_train_9d, X_test_9d, y_test_9d, '9d_sma')\nplot_model_data(history_9d, '9D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_11d = train_model(model_11d, X_train_11d, y_train_11d, X_test_11d, y_test_11d, '11d_sma')\nplot_model_data(history_11d, '11D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_13d = train_model(model_13d, X_train_13d, y_train_13d, X_test_13d, y_test_13d, '13d_sma')\nplot_model_data(history_13d, '13D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_15d = train_model(model_15d, X_train_15d, y_train_15d, X_test_15d, y_test_15d, '15d_sma')\nplot_model_data(history_15d, '15D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_17d = train_model(model_17d, X_train_17d, y_train_17d, X_test_17d, y_test_17d, '17d_sma')\nplot_model_data(history_17d, '17D SMA')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_all = train_model(model_all, X_train_all, y_train_all, X_test_all, y_test_all, 'all_sma')\nplot_model_data(history_all, 'ALL SMAs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation\n\n## Process\n\nModels are evaluated on the test set:\n\n- **Prediction**: Scaled predictions are inverse-transformed.\n- **Metrics**:\n  - MAE (Mean Absolute Error).\n  - MSE (Mean Squared Error).\n  - RMSE (Root Mean Squared Error).\n  - R² (Goodness of fit).\n  - MAPE (Mean Absolute Percentage Error).\n  - Directional Accuracy (% correct direction).\n- **Visualization**: True vs. predicted prices.","metadata":{}},{"cell_type":"code","source":"the_best_models_list = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create inverse transformation helper\ndef inverse_transform_prediction(scaler, scaled_prediction, features):\n    temp = np.zeros((len(scaled_prediction), len(features)))\n    temp[:, features.index(target_col)] = scaled_prediction\n    return scaler.inverse_transform(temp)[:, features.index(target_col)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, features, scaler, X_test, y_test, model_name, model_id=None):\n    # Predict on test set\n    test_predictions = model.predict(X_test).flatten()\n    \n    # Inverse transform\n    y_test_true = inverse_transform_prediction(scaler, y_test, features)\n    y_test_pred = inverse_transform_prediction(scaler, test_predictions, features)\n    \n    # Calculate metrics\n    mae = mean_absolute_error(y_test_true, y_test_pred)\n    mse = mean_squared_error(y_test_true, y_test_pred)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(y_test_true, y_test_pred)\n    mape = mean_absolute_percentage_error(y_test_true, y_test_pred)\n    \n    # Directional accuracy\n    direction_true = np.diff(y_test_true) > 0\n    direction_pred = np.diff(y_test_pred) > 0\n    directional_acc = np.mean(direction_true == direction_pred)\n    \n    print(f\"{model_name} MAE: {mae:.2f}\")\n    print(f\"{model_name} MSE: {mse:.2f}\")\n    print(f\"{model_name} RMSE: {rmse:.2f}\")\n    print(f\"{model_name} R² Score: {r2:.4f}\")\n    print(f\"{model_name} Directional Accuracy: {directional_acc*100:.2f}%\")\n    print(f\"{model_name} Mean Absolute Percentage Error: {mape*100:.2f}%\")\n    \n    if mape*100 < 2.5 and 'd_' in model_id:\n        the_best_models_list.append(model_id)\n    \n    # %%\n    # Visual comparison\n    plt.figure(figsize=(12,6))\n    plt.plot(y_test_true, label='True Price')\n    plt.plot(y_test_pred, label='Predicted Price')\n    plt.title(f'Test Set Predictions vs Actuals - {model_name}')\n    plt.xlabel('Time Steps')\n    plt.ylabel('Price (USD)')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Models\n\n- Simple data.\n- Individual SMAs (5D to 17D).\n- All SMAs.\n\nThis assesses predictive accuracy comprehensively.","metadata":{}},{"cell_type":"code","source":"evaluate_model(model_simple, features_simple, scaler_simple, X_test_simple, y_test_simple, 'Without SMA', 'no_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_5d, features_5d, scaler_5d, X_test_5d, y_test_5d, '5D', '5d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_7d, features_7d, scaler_7d, X_test_7d, y_test_7d, '7D', '7d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_9d, features_9d, scaler_9d, X_test_9d, y_test_9d, '9D', '9d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_11d, features_11d, scaler_11d, X_test_11d, y_test_11d, '11D', '11d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_13d, features_13d, scaler_13d, X_test_13d, y_test_13d, '13D', '13d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_15d, features_15d, scaler_15d, X_test_15d, y_test_15d, '15D', '15d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_17d, features_17d, scaler_17d, X_test_17d, y_test_17d, '17D', '17d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_all, features_all, scaler_all, X_test_all, y_test_all, 'ALL', 'all_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Future Prediction\n\n## Process\n\nThe `predict_future_days` function forecasts 10 days:\n\n- **Method**: Iteratively predicts using the last test sequence.\n- **Output**: Inverse-transformed predictions with dates.\n- **Evaluation**: Compares to actual data (MSE, MAE, RMSE, R², MAPE).\n- **Visualization**: Plots last 200 days with predictions.","metadata":{}},{"cell_type":"code","source":"the_best_future_models_list = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_future_days(dataframe, model, features, scaler, X_test, model_name, model_id=None):\n    # Predict next days\n    predictions = []\n    last_sequence = X_test[-1].copy()\n    \n    for _ in range(FUTURE_DAYS):\n        current_pred = model.predict(last_sequence.reshape(1, SEQ_LENGTH, len(features)))[0,0]\n        new_row = last_sequence[-1].copy()\n        new_row[features.index(target_col)] = current_pred\n        last_sequence = np.vstack([last_sequence[1:], new_row])\n        predictions.append(current_pred)\n    \n    # Inverse transform\n    temp_array = np.zeros((len(predictions), len(features)))\n    temp_array[:, features.index(target_col)] = predictions\n    predicted_prices = scaler.inverse_transform(temp_array)[:, features.index(target_col)]\n    \n    # Generate dates\n    last_date = dataframe.index[-1]\n    prediction_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=FUTURE_DAYS)\n    \n    # Create DataFrame\n    predictions_df = pd.DataFrame({\n        'Date': last_n_days_data.Date,\n        'Actual Price': last_n_days_data.Close,\n        'Predicted Price': predicted_prices\n    })\n    \n    # Print numerical predictions\n    print(\"\\nGoogle Stock Price Predictions for Next FUTURE_DAYS Days:\")\n    print(predictions_df.round(2).to_string(index=False))\n    \n    mse = mean_squared_error(last_n_days_data.Close, predicted_prices)\n    mae = mean_absolute_error(last_n_days_data.Close, predicted_prices)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(last_n_days_data.Close, predicted_prices)\n    mape = mean_absolute_percentage_error(last_n_days_data.Close, predicted_prices)\n    \n    print(f'{model_name} MSE based on last {FUTURE_DAYS} days prediction: {mse}')\n    print(f'{model_name} MAE based on last {FUTURE_DAYS} days prediction: {mae}')\n    print(f'{model_name} RMSE based on last {FUTURE_DAYS} days prediction: {rmse}')\n    print(f'{model_name} R^2 based on last {FUTURE_DAYS} days prediction: {r2}')\n    print(f'{model_name} MAPE based on last {FUTURE_DAYS} days prediction: {mape*100:.4f}%')\n\n    if mape*100 < 1.5 and 'd_' in model_id:\n        the_best_future_models_list.append(model_id)\n    \n    df1_subset = dataframe[['Close']] \n    df2_subset = predictions_df[['Date', 'Actual Price']] \n    df2_renamed = df2_subset[['Date', 'Actual Price']].rename(columns={'Actual Price': 'Close'})\n    df2 = df2_renamed.set_index('Date')\n    result = pd.concat([df1_subset, df2], axis=0)\n    \n    # Plot predictions\n    plt.figure(figsize=(12,6))\n    plt.plot(result[-50:], 'b-', label='Historical')\n    plt.plot(last_n_days_data['Date'], predicted_prices, 'r-', label='Predicted')\n    plt.title(f'Google Stock Price Prediction - Last 50 days - {model_name}')\n    plt.xlabel('Date')\n    plt.ylabel('Price (USD)')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Models\n\nPredictions for:\n- Simple data.\n- Individual SMAs.\n- All SMAs.\n\nThis tests forecasting ability.","metadata":{}},{"cell_type":"code","source":"predict_future_days(df, model_simple, features_simple, scaler_simple, X_test_simple, 'Without SMA', 'no_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_5d, features_5d, scaler_5d, X_test_5d, '5D', '5d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_7d, features_7d, scaler_7d, X_test_7d, '7D', '7d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_9d, features_9d, scaler_9d, X_test_9d, '9D', '9d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_11d, features_11d, scaler_11d, X_test_11d, '11D', '11d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_13d, features_13d, scaler_13d, X_test_13d, '13D', '13d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_15d, features_15d, scaler_15d, X_test_15d, '15D', '15d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_17d, features_17d, scaler_17d, X_test_17d, '17D', '17d_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_all, features_all, scaler_all, X_test_all, 'ALL', 'all_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Combining Models (Best SMAs)\n\nModels with MAPE < 3.0 are selected automatically.\n\n- **Features**: 'Open', 'High', 'Low', 'Close', ...\n- **Process**: Trains, evaluates, predicts.\n- **Visualization**: Candlestick chart with best SMAs.","metadata":{}},{"cell_type":"code","source":"print(f'The selected models: {the_best_models_list}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_best = ['Open', 'High', 'Low', 'Close'] + the_best_models_list\nX_train_best, X_test_best, y_train_best, y_test_best, scaler_best = feature_selection(df, features_best)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_best = create_model(X_train_best)\nmodel_best.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_best = train_model(model_best, X_train_best, y_train_best, X_test_best, y_test_best, 'best_sma')\nplot_model_data(history_best, 'The Best SMAs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_best, features_best, scaler_best, X_test_best, y_test_best, 'The Best SMAs', 'best_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_best, features_best, scaler_best, X_test_best, 'The Best SMAs', 'best_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the candlestick chart\nfig = go.Figure(data=[go.Candlestick(\n    x=plot_df['Date'],  # Date on the x-axis\n    open=plot_df['Open'],  # Open prices\n    high=plot_df['High'],  # High prices\n    low=plot_df['Low'],  # Low prices\n    close=plot_df['Close'],  # Close prices\n    name='Google Stock Market in 2025'\n)])\n\n# Customize the layout\nfig.update_layout(\n    title='Google Stock Price History - 2025 - The Best SMA Models',\n    xaxis_title='Date',\n    yaxis_title='Price (USD)',\n    xaxis_rangeslider_visible=False\n)\n\ncolors = ['blue', 'orange', 'red', 'purple', 'brown', 'pink', 'gray']\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['Close'], line_color='green', name='Close', mode='lines'))\n\nfor i, item in enumerate(the_best_models_list):\n    fig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df[item], line_color=colors[i], name='-'.join(item.upper().split('_')), mode='lines'))\n\n\n# Show the plot\ndisplay(HTML(fig.to_html(include_plotlyjs=True)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The Best Models based on Future Predictions\n\nModels Future Predictions with MAPE < 2.0 are selected automatically.\n- **Features**: 'Open', 'High', 'Low', 'Close', ...\n- **Process**: Trains, evaluates, predicts.\n- **Visualization**: Candlestick chart with the best SMAs based on future predictions.\n\nThese combinations aim to enhance prediction accuracy.","metadata":{}},{"cell_type":"code","source":"print(f'The selected models based on predictions: {the_best_future_models_list}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature selection and normalization\nfeatures_future_best = ['Open', 'High', 'Low', 'Close'] + the_best_future_models_list\nX_train_future_best, X_test_future_best, y_train_future_best, y_test_future_best, scaler_future_best = feature_selection(df, features_future_best)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_future_best = create_model(X_train_future_best)\nmodel_future_best.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_future_best = train_model(model_future_best, X_train_future_best, y_train_future_best, X_test_future_best, y_test_future_best, 'best_future_sma')\nplot_model_data(history_best, 'The Best Future SMAs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model_future_best, features_future_best, scaler_future_best, X_test_future_best, y_test_future_best, 'The Best Future SMAs', 'best_future_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_future_days(df, model_future_best, features_future_best, scaler_future_best, X_test_future_best, 'The Best Future SMAs', 'best_future_sma')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the candlestick chart\nfig = go.Figure(data=[go.Candlestick(\n    x=plot_df['Date'],  # Date on the x-axis\n    open=plot_df['Open'],  # Open prices\n    high=plot_df['High'],  # High prices\n    low=plot_df['Low'],  # Low prices\n    close=plot_df['Close'],  # Close prices\n    name='Google Stock Market in 2025'\n)])\n\n# Customize the layout\nfig.update_layout(\n    title='Google Stock Price History - 2025 - The Best Future SMA Models',\n    xaxis_title='Date',\n    yaxis_title='Price (USD)',\n    xaxis_rangeslider_visible=False\n)\n\nfig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df['Close'], line_color='green', name='Close', mode='lines'))\n\nfor i, item in enumerate(the_best_future_models_list):\n    fig.add_trace(go.Scatter(x=plot_df['Date'], y=plot_df[item], line_color=colors[i], name='-'.join(item.upper().split('_')), mode='lines'))\n\n\n# Show the plot\ndisplay(HTML(fig.to_html(include_plotlyjs=True)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Summary\n\nThis notebook explores the use of Long Short-Term Memory (LSTM) neural networks to predict Google stock prices, focusing on the impact of different Simple Moving Average (SMA) configurations. The analysis includes several models:\n\n- **Baseline Model**: An LSTM model without SMAs.\n- **Individual SMA Models**: Models incorporating SMAs with window sizes of 5, 7, 9, 11, 13, 15, and 17 days.\n- **Combined SMA Model**: A model using all SMA window sizes together.\n- **Top-Performing SMA Model**: Two models combining the best-performing SMAs from the individual tests.\n\nThe models are evaluated using key metrics:\n- Mean Absolute Error (MAE)\n- Mean Squared Error (MSE)\n- Root Mean Squared Error (RMSE)\n- R² Score\n- Mean Absolute Percentage Error (MAPE)\n- Directional Accuracy\n\n### Visualizations\nInteractive candlestick charts overlaid with SMA trends are included to highlight price movements and model performance, offering clear visual insights into the effectiveness of the SMA-enhanced predictions.\n\n### Conclusion\nIncorporating multiple SMAs into LSTM models significantly improves stock price forecasting accuracy. This approach provides a robust framework for understanding market trends and can be a valuable tool for financial analysis.","metadata":{}}]}